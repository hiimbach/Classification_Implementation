import torch
import os
import sys

from PIL import Image
from torchvision import transforms

ROOT = os.getcwd()
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))
    
from model.resnet import ResNet50
from utils.data_loader import custom_loader, filenames_to_tensor, read_file_classnames


class MushroomClassifier():
    def __init__(self, weight_path=None, model_path=None):
        '''
        Arguments:
            file_names_path (str): The path to the file name, generated by utils.TrainLoop,
                                    structured as name1, name2, name3,... 
            weight_path (str): The path of ResNet50 checkpoint
            model_path (str): The path of the scripted model
        
        '''
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        if model_path:
            self.model = torch.jit.load(model_path)
        else:
            self.model = ResNet50(9)
            if weight_path:
                self.model.load_state_dict(torch.load(weight_path, map_location=device))
                
        
            
        self.tf = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
        
        self.model.eval()
        
        
    @torch.inference_mode()
    def predict(self, path, batch_size=4) -> int:
        if not os.path.exists(path):
            print("Not found path")
            return 
        else:
            # If there is a image
            if os.path.isfile(path):
                img = Image.open(path)
                tensor = self.tf(img)
                tensor.unsqueeze_(dim=0)
                
                out = self.model(tensor)
                _, preds = torch.max(out, dim=1)
                
                return {path: int(preds[0])}
            
            # If the path is a folder 
            elif os.path.isdir(path):
                all_paths = [os.path.join(path, file) for file in os.listdir(path)]
                
                # Load data into batches
                path_batches = custom_loader(all_paths, batch_size)
                all_preds = []
                for path_batch in path_batches:
                    tensor = filenames_to_tensor(path_batch, self.tf)
                    out = self.model(tensor)
                    _, preds = torch.max(out, dim=1)
                    all_preds += (preds.tolist())
                
                result = {}
                for i in range(len(all_paths)):
                    result[all_paths[i]] = all_preds[i]
                    
                return result
                    
            
            else:
                print("Path must belongs to an image or a folder")
                return    
                    
            

if __name__ == '__main__':
    classifier = MushroomClassifier(weight_path='weights/last_ckpt3.pt')
    origin_path = "data/mushrooms/Suillus"
    result = classifier.predict(origin_path)
    print(result)

















# img_size = 640
# # model = ViT(
# #     image_size = img_size,
# #     patch_size = 32,
# #     num_classes = 9,
# #     dim = 1024,
# #     depth = 6,
# #     heads = 16,
# #     mlp_dim = 2048,
# #     dropout = 0.1,
# #     emb_dropout = 0.1
# # )

# model = ResNet50(9)

# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# tf = transforms.Compose([
#     transforms.Resize([640,640]),
#     transforms.ToTensor()
# ])


# path = "mushrooms_test/Agaricus"
# weight_path = "weights/last_ckpt.pt"
# model.load_state_dict(torch.load(weight_path, map_location=device))


# # Infer
# def inference(model, path, transform, weight_path=None, batch_size=None):
#     # Check path is dir or file:
#     if not os.path.exists(path):
#         print("No path")
#     if os.path.isfile(path):
#         img = Image.open(path)
#         data_loader = [[img]]
#         print("Is file")
#     elif os.path.isdir(path):
#         if not batch_size:
#             print("If path is directory, please choose batch size")
#             return
#         else:
#             img_list = [os.path.join(path, item) for item in os.listdir(path)]
#             data_len = len(img_list)
#             data_loader = []
#             i = 0
#             # Load into batches
#             while (i+batch_size) < data_len:
#                 path_batch = img_list[i:i+batch_size]
#                 data_loader.append(path_batch)
#                 i += batch_size
#             print("Is dir")
#     else:
#         print("Wtf")
#         return
    
#     # Infer
#     result = {}
#     with torch.no_grad():
#         for path_batch in data_loader:
#             print(path_batch)
#             img_batch = filename_to_tensor(path_batch, transform)
            
#             # Use ViT for prediction
#             outputs = model(img_batch)
#             _, predicted = torch.max(outputs, dim=1)
#             assert(len(predicted) == len(path_batch))
            
#             for k in range(len(path_batch)):
#                 result[path_batch[k]] = predicted[k]
    
#     return result

# print(inference(model, path, tf, batch_size=8))